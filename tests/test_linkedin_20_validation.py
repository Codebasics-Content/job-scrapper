"""LinkedIn 1000-job scale test - JobSpy scraper
Tests: Job descriptions, skill extraction, DB storage
RL: +10 if all pass, -15 if failures
"""
import asyncio
from datetime import datetime
from pathlib import Path
import sys

sys.path.insert(0, str(Path(__file__).parent.parent))

from src.scraper.multi_platform_service import scrape_jobs_with_skills


async def test_linkedin_20_jobs():
    """Test LinkedIn scraping: 100 AI Engineer jobs with descriptions + skills"""
    print("ğŸ§ª LinkedIn 100-Job Scale Test")
    print("=" * 60)
    print(f"â° Start Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ğŸ¯ Target: 100 AI Engineer jobs from LinkedIn")
    print(f"ğŸ”§ Platform: JobSpy library\n")
    
    db_path = Path(__file__).parent.parent / "jobs.db"
    print(f"ğŸ’¾ Database: {db_path}\n")
    
    # Scrape 100 LinkedIn jobs
    print("ğŸš€ Starting scrape...")
    start = datetime.now()
    jobs = await scrape_jobs_with_skills(
        platforms=["linkedin"],
        keyword="AI Engineer",
        location="",  # Empty string for broad search per JobSpy docs
        limit=100,
        store_to_db=True  # âœ… STORE TO DATABASE DURING SCRAPING
    )
    duration = (datetime.now() - start).total_seconds()
    print(f"\nâ±ï¸  Scraping completed in {duration:.1f}s ({duration/60:.1f} min)")
    
    # Validation
    print(f"\nğŸ“Š Validating {len(jobs)} jobs...")
    print(f"ğŸ“‹ Checking: Job descriptions (>50 chars) + Skills extraction")
    print(f"ğŸ“¦ Batch Size: 10 jobs per batch\n")
    
    passed = 0
    failed = 0
    batch_start = datetime.now()
    
    for idx, job in enumerate(jobs, 1):
        has_desc = bool(job.job_description and len(job.job_description) > 50)
        has_skills = bool(job.skills and len(job.skills) > 0)
        
        if has_desc and has_skills:
            passed += 1
        else:
            failed += 1
            print(f"  âŒ Job {idx}: desc={len(job.job_description) if job.job_description else 0}, skills={job.skills}")
        
        # Batch logging every 10 jobs
        if idx % 10 == 0:
            batch_time = (datetime.now() - batch_start).total_seconds()
            print(f"\n  ğŸ“¦ BATCH {idx//10}: Jobs {idx-9}-{idx}")
            print(f"     âœ… Passed in batch: {passed - (passed - 10 if idx > 10 else 0)}")
            print(f"     â±ï¸  Batch time: {batch_time:.2f}s")
            print(f"     ğŸ“Š Total progress: {idx}/{len(jobs)} ({idx/len(jobs)*100:.1f}%)")
            print(f"     âœ… Cumulative passed: {passed}")
            print(f"     âŒ Cumulative failed: {failed}\n")
            batch_start = datetime.now()
    
    # Results
    print("\n" + "="*60)
    print("ğŸ“ˆ RESULTS SUMMARY")
    print("="*60)
    
    if len(jobs) == 0:
        print("âš ï¸  No jobs scraped (all were duplicates or LinkedIn has no new jobs)")
        print(f"ğŸ’¡ Suggestion: Clear database OR use different search keyword")
        print(f"â±ï¸  Total Time: {duration:.1f}s ({duration/60:.1f} min)")
        print(f"ğŸ’¾ Database: {db_path}")
        return
    
    print(f"âœ… Passed: {passed}/{len(jobs)} ({passed/len(jobs)*100:.1f}%)")
    print(f"âŒ Failed: {failed}/{len(jobs)} ({failed/len(jobs)*100:.1f}%)")
    print(f"â±ï¸  Total Time: {duration:.1f}s ({duration/60:.1f} min)")
    print(f"ğŸ’¾ Database: {db_path}")
    print(f"âš¡ Speed: {len(jobs)/duration:.2f} jobs/sec")
    print(f"â° End Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # RL scoring
    if failed == 0:
        print(f"ğŸ‰ RL REWARD: +10 (100% success)")
        return {"reward": 10, "passed": passed, "failed": 0}
    else:
        print(f"âš ï¸  RL PENALTY: -15 ({failed} failures)")
        return {"penalty": -15, "passed": passed, "failed": failed}


if __name__ == "__main__":
    result = asyncio.run(test_linkedin_20_jobs())
    sys.exit(0 if result.get("failed", 0) == 0 else 1)
